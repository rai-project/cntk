name: Xception # name of your model
framework:
  name: CNTK # framework for the model
  version: 2.3 # framework version contraint
version: 1.0 # version information in semantic version format
container: # containers used to perform model prediction
           # multiple platforms can be specified
  amd64:
    gpu: raiproject/carml-cntk:amd64-cpu
    cpu: raiproject/carml-cntk:amd64-gpu
  ppc64le:
    cpu: raiproject/carml-cntk:ppc64le-gpu
    gpu: raiproject/carml-cntk:ppc64le-gpu
description: >
  An interpretation of Inception modules in convolutional neural networks as being an intermediate step in-between
  regular convolution and the depthwise separable convolution operation (a depthwise convolution followed by a pointwise convolution).
  In this light, a depthwise separable convolution can be understood as an Inception module with a maximally large number of towers.
  This observation leads us to propose a novel deep convolutional neural network architecture inspired by Inception, where Inception
  modules have been replaced with depthwise separable convolutions. We show that this architecture, dubbed Xception, slightly outperforms
  Inception V3 on the ImageNet dataset (which Inception V3 was designed for), and significantly outperforms Inception V3 on a larger image
  classification dataset comprising 350 million images and 17,000 classes. Since the Xception architecture has the same number of parameters
  as Inception V3, the performance gains are not due to increased capacity but rather to a more efficient use of model parameters. 
references: # references to papers / websites / etc.. describing the model
  - https://github.com/soeaver/cntk-model/tree/master/cls
  - https://github.com/BVLC/caffe/pull/5665/files
  - https://github.com/fchollet/deep-learning-models/blob/master/xception.py
  - https://arxiv.org/abs/1610.02357
# license of the model
license: unrestricted
# inputs to the model
inputs:
  # first input type for the model
  - type: image
    # description of the first input
    description: the input image
    parameters: # type parameters
      dimensions: [3, 299, 299]
      mean: [128, 128, 128]
      scale: 128
output:
  # the type of the output
  type: feature
  # a description of the output parameter
  description: the output label
  parameters:
    # type parameters
    features_url: http://s3.amazonaws.com/store.carml.org/synsets/imagenet/synset.txt
    features_checksum: 4d234b5833aca44928065a180db3016a
model: # specifies model graph and weights resources
  graph_path: http://s3.amazonaws.com/store.carml.org/models/caffe/xception/deploy_xception.prototxt
  weights_path: http://s3.amazonaws.com/store.carml.org/models/caffe/xception/xception.caffemodel
  is_archive: false # if set, then the base_url is a url to an archive
                    # the graph_path and weights_path then denote the
                    # file names of the graph and weights within the archive
  graph_checksum: d0df3aaaa43e4b82e4794b89420b7067
  weights_checksum: cad1c76e17becaeb0bde0351cfb6dba8
attributes: # extra network attributes
  kind: CNN # the kind of neural network (CNN, RNN, ...)
  training_dataset: ImageNet # dataset used to for training
  manifest_author: abduld
